# Project Progress & Next Steps Checklist

A concise, professional overview of what we have accomplished so far and the planned activities ahead.

---

## ‚úîÔ∏è Completed

### 1. Environment & Setup

- [x] Created Conda environment **credit-risk** (Python 3.10).
- [x] Registered Jupyter kernel **Python (credit-risk)**.

### 2. Data Ingestion & Dictionary

- [x] Loaded `application_train.csv` and `application_test.csv`.
- [x] Loaded and standardized **HomeCredit_columns_description.csv**.

### 3. Data Understanding

- [x] Inspected shapes and previewed head of both train (48 744 √ó 121) and test (307 511 √ó 122) sets.
- [x] Computed data types and missing‚Äêvalue rates for all features.
- [x] Identified top missing features in both datasets (real-estate attributes ~‚Äâ68‚Äì70% missing).

### 4. Data Dictionary Consolidation

- [x] Merged train summary with feature dictionary (219 documented variables).
- [x] Highlighted undocumented high-missing features.

### 5. Missing‚ÄêValue Handling

- [x] Created binary ‚Äú\_missing_flag‚Äù indicators for high-missing numeric variables.
- [x] Imputed numeric features with medians; categorical features with ‚ÄúUnknown.‚Äù
- [x] Verified **zero** missing values remain.
- [x] Documented imputation approach and pandas warnings for future refactor.

---

## ‚è≥ To Do

### 6. Feature Scaling & Encoding

- [ ] Apply **RobustScaler** to all numeric features to mitigate outliers.
- [ ] One-hot encode low-cardinality categoricals.
- [ ] Target-encode high-cardinality categoricals.

### 7. Exploratory Data Analysis (EDA)

- [ ] Univariate distributions and summary statistics.
- [ ] Bivariate analysis vs. **TARGET** (boxplots, violin plots).
- [ ] Correlation heatmap and multicollinearity checks.
- [ ] Outlier detection and treatment plan.

### 8. Feature Engineering

- [ ] Aggregate auxiliary tables (`bureau.csv`, `previous_application.csv`, etc.) at client level.
- [ ] Create behavioral indicators (e.g. payment ratios, utilization rates).
- [ ] Temporal features (recency, application frequency).
- [ ] Interaction terms and polynomial features (if justified).

### 9. Model Development

- [ ] Split data into stratified K-folds (or time-based splits).
- [ ] Train baseline **Logistic Regression** with pipeline.
- [ ] Train tree-based models (Random Forest, XGBoost, LightGBM, CatBoost).
- [ ] Hyperparameter tuning with **Optuna**.
- [ ] Evaluate metrics: AUC-ROC, KS, Precision@k, Recall@k.

### 10. Model Explainability

- [ ] Generate **SHAP** global summary and dependence plots.
- [ ] Create local explanations (force plots) for sample clients.
- [ ] Document key drivers for stakeholder communication.

### 11. Validation & Monitoring

- [ ] Perform stability analysis (PSI, performance drift).
- [ ] Define retraining triggers and schedule.
- [ ] Implement model monitoring (Evidently.ai or WhyLabs).

### 12. Deployment & Reporting

- [ ] Build scoring **API** with FastAPI + Docker.
- [ ] Develop interactive **Streamlit** dashboard (or Power BI).
- [ ] Prepare final **README**, **presentation deck**, and **project narrative**.

---

> **Next immediate step:**  
> Proceed with Feature Scaling & Encoding (Section 6), then return here to tick off progress.

---

perfeito ‚Äî aqui vai um ‚Äúmapa do projeto‚Äù do JEITO MAIS CLARO poss√≠vel: o que fizemos, por que fizemos, o que deu, e o que vamos atacar agora.

---

# 1) Problema de neg√≥cio (o que queremos)

Prever **probabilidade de inadimpl√™ncia (TARGET=1)** para:

- **Tomada de decis√£o** (aprova√ß√£o/limite/pre√ßo) e **prioriza√ß√£o** (collections e monitoramento).
- Entrega **interpret√°vel** (explica√ß√µes SHAP, curva KS, thresholds) e **aud√≠vel** (pipeline reprodut√≠vel).

KPIs principais:

- **AUC-ROC** e **KS** (discrimina√ß√£o global).
- **Precision\@20%** e **Recall\@20%** (qualidade do top-20% mais arriscado ‚Äì √∫til para priorizar a√ß√µes).
- **Brier score** e **reliability curve** (calibra√ß√£o das probabilidades como PD).

---

# 2) Dados & EDA (o que vimos)

- Bases principal: `application_train.csv` (com TARGET) e `application_test.csv`.
- **Missing alto** e concentrado nas vari√°veis ‚Äúimobili√°rias‚Äù (`COMMONAREA_*`, `LIVINGAPARTMENTS_*`, `YEARS_BUILD_*` etc., >60%).
- Dicion√°rio `HomeCredit_columns_description.csv` usado para documentar vari√°veis.
- Checagem de tipos + padr√£o de aus√™ncias no train vs. test para evitar surpresas no scoring.

**Decis√£o:** tratar tudo **dentro da pipeline** (sem ‚Äúpr√©-tratar‚Äù fora), para evitar vazamento e garantir reprodutibilidade.

---

# 3) Pr√©-processamento (profissional e sem vazamento)

Usamos um **`ColumnTransformer`** com tr√™s fluxos:

1. **Num√©ricas** ‚Üí `SimpleImputer(median)` + `RobustScaler` (robusto a outliers).
2. **Categ√≥ricas de baixa cardinalidade** ‚Üí `OneHotEncoder(handle_unknown='ignore')`.
3. **Categ√≥ricas de alta cardinalidade** ‚Üí `TargetEncoder` (aprende m√©dias condicionais **apenas no treino do fold**).

Tudo embrulhado em **`Pipeline`**, aplicado **dentro do CV**.
Isso garante que:

- encoders e imputers **n√£o ‚Äúolham‚Äù o validation fold**;
- scoring em produ√ß√£o replica exatamente o que aconteceu no treino.

Tamb√©m **persistimos os nomes das features transformadas** (`artifacts/feature_names_logreg.csv`, 170 colunas) ‚Äî √∫til para SHAP e auditoria.

---

# 4) Baseline ‚Äî Logistic Regression (L2)

Rodamos 5-fold **estratificado** com `class_weight="balanced"`.

**OOF (fora-da-amostra):**

- **AUC ‚âà 0.746**
- **KS ‚âà 0.365**
- **P\@20 ‚âà 0.200**
- **R\@20 ‚âà 0.500**

Coment√°rios:

- √â um baseline **s√≥lido** e interpret√°vel.
- Apareceu `ConvergenceWarning` (lbfgs) ‚Üí esperado em espa√ßo de features alto (OHE + TE). Mitigamos com `max_iter‚Üë` e op√ß√£o de `solver="saga"` com L2.

---

# 5) Elastic Net (saga) ‚Äî experimento e li√ß√£o

Testamos **log√≠stica com elastic net** (`penalty='elasticnet'`, `solver='saga'`) para encolher coeficientes ruidosos.

**Resultado:**

- **Mais lenta** (horas por fold em alguns casos) e **m√©tricas piores** (\~AUC 0.732, KS \~0.349, P\@20 \~0.194).
  **Decis√£o:** **descartar** para esse dataset (alto custo/baixo benef√≠cio). Mantemos **L2** como baseline linear.

---

# 6) Calibra√ß√£o de probabilidade (diagn√≥stico)

A **reliability curve** ficou **abaixo da diagonal** ‚áí o modelo **superestima PD** (over-prediction).
Isso √© comum com `class_weight="balanced"` e dados desbalanceados.

**Plano:** **Isotonic Regression por fold** (fit‚Üícalibrate‚Üívalidate sem vazamento) para melhorar **Brier** e alinhar PDs sem mexer muito na AUC/KS.

---

# 7) LightGBM + Optuna (o avan√ßo)

Subimos para **√°rvores de gradiente** (LightGBM) com **busca de hiperpar√¢metros** via Optuna.

Pontos t√©cnicos importantes que resolvemos:

- **LightGBM 4.x** n√£o aceita `early_stopping_rounds` no `.fit()` estilo sklearn ‚Üí usamos **callbacks** (`lgb.early_stopping`).
- `eval_set` dentro de `Pipeline` **n√£o passa pelo preprocessor** ‚Üí ent√£o **fitamos e transformamos** (`preprocessor.fit/transform`) **fora** e passamos **matriz num√©rica** para o LGBM (sem objetos).

**OOF por fold (seus n√∫meros):**

- Fold1: AUC 0.757 | KS 0.385 | P\@20 0.211 | R\@20 0.523
- Fold2: AUC 0.768 | KS 0.396 | P\@20 0.217 | R\@20 0.538
- Fold3: AUC 0.759 | KS 0.388 | P\@20 0.211 | R\@20 0.523
- Fold4: AUC 0.766 | KS 0.404 | P\@20 0.214 | R\@20 0.530
- Fold5: AUC 0.757 | KS 0.383 | P\@20 0.209 | R\@20 0.518

**M√©dia aproximada:**

- **AUC ‚âà 0.761** (‚Üë vs 0.746 baseline)
- **KS ‚âà 0.391** (‚Üë vs 0.365)
- **P\@20 ‚âà 0.212** (‚Üë vs 0.200)
- **R\@20 ‚âà 0.526** (‚Üë vs 0.500)

üí° **Leitura de neg√≥cio:** no **top-20%** mais arriscado, **capturamos mais inadimplentes e com maior precis√£o**, mantendo discrimina√ß√£o global melhor. Ou seja, **prioriza√ß√£o melhor** com o mesmo esfor√ßo operacional.

---

# 8) Onde estamos agora & o que vamos resolver j√°

## O problema imediato

1. **Calibrar as probabilidades do LightGBM** (como PD confi√°vel).

   - Objetivo: **reduzir Brier** e alinhar a **reliability curve** √† diagonal.
   - Estrat√©gia: **Isotonic** por fold (fit‚Üícalibrate‚Üívalidate).

2. **Explicabilidade** com **SHAP**:

   - **Global** (quais vari√°veis puxam o risco para cima/baixo em m√©dia).
   - **Local** (explicar um cliente espec√≠fico ‚Äî √≥timo para storytelling).

3. **Thresholding**:

   - Escolher um **cutoff** que maximize KS/Youden **ou** que maximize **lucro** dado custos de FP/FN (se voc√™ tiver esses custos).
   - Alternativa: **score bins** (Very High/High/Medium/Low) com cortes coerentes e est√°veis.

## Por que isso?

- **AUC/KS** dizem ‚Äúqu√£o bem‚Äù separamos ‚Äî **n√£o** dizem se **probabilidade** est√° calibrada.
- Para **reportar PD** (e usar em pricing/limite), **calibra√ß√£o** √© cr√≠tica.
- **SHAP** cria confian√ßa: mostra **drivers de risco** de forma clara e defens√°vel.
- **Threshold/binning** traduz o modelo para **decis√£o operacional** (quem aprovar, quem revisar, quem cobrar primeiro).

---

# 9) Pr√≥ximos passos (em ordem)

**Agora**

1. Rodar **calibra√ß√£o isot√¥nica** do LGBM (tenho a c√©lula pronta ‚Äî voc√™ j√° rodou a parte log√≠stica; a do LGBM est√° no meu √∫ltimo bloco).
2. Gerar **reliability curve (raw vs calibrated)** e **Brier** (antes/depois).
3. Gerar **SHAP** (summary bar + summary dot + exemplo local).

**Em seguida**
4\) **Escolher cutoff** (max KS / custo-benef√≠cio) e/ou **definir score bands**.
5\) **Persistir artefatos** (`preprocessor.joblib`, `lgbm_model.txt` ou `.joblib`, `isotonic.pkl`, `feature_names.csv`, `best_params.json`) + fun√ß√£o `score(df)`.

**Depois (para fechar n√≠vel s√™nior)**
6\) **Feature engineering** com dados auxiliares (`bureau`, `previous_application`, `installments`, `credit_card_balance`, `POS_CASH`), agrega√ß√µes por cliente (p. ex.: atraso m√©dio, max atraso, raz√£o valor parcelado/limite, n√∫mero de contratos ativos etc.).

- Isso costuma dar **salto grande de AUC/KS** nesse case.

7. **Drift & Monitoring** com Evidently (opcional) + **tracking** com MLflow (opcional).
8. **Entrega**: Streamlit simples (perfil de risco + SHAP local) e README üî•.

---

# 10) Resumo em uma linha

**J√° elevamos a performance saindo da regress√£o para LightGBM (‚ÜëAUC/KS/P\@20/R\@20); agora vamos calibrar as probabilidades para virar PD confi√°vel e explicar o modelo com SHAP, fechando com thresholds/bins para opera√ß√£o.**

Se quiser, eu j√° **colo agora**:

- a **c√©lula de calibra√ß√£o isot√¥nica do LGBM** (pronta pra rodar),
- a **c√©lula de SHAP** (global/local),
- e a **c√©lula de persist√™ncia + fun√ß√£o `score()`** para produ√ß√£o.
#   c r e d i t - r i s k  
 #   c r e d i t - r i s k  
 